{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFOTiqrtNvyy"
   },
   "source": [
    "# Install Transformers Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hkhc10wNrGt",
    "outputId": "a716c4be-0052-4f0f-bd74-3861993892ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==3.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\king\\anaconda3\\lib\\site-packages (from transformers==3.0.0) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\king\\anaconda3\\lib\\site-packages (from transformers==3.0.0) (4.36.1)\n",
      "Collecting sacremoses (from transformers==3.0.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "Requirement already satisfied: requests in c:\\users\\king\\anaconda3\\lib\\site-packages (from transformers==3.0.0) (2.22.0)\n",
      "Collecting regex!=2019.12.17 (from transformers==3.0.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/3f/40c8db23e022ccc9eb9fc0f39202af49c8614b22990b2e7129c2543f2da5/regex-2020.11.13-cp37-cp37m-win_amd64.whl (269kB)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\king\\anaconda3\\lib\\site-packages (from transformers==3.0.0) (0.1.85)\n",
      "Requirement already satisfied: packaging in c:\\users\\king\\anaconda3\\lib\\site-packages (from transformers==3.0.0) (19.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\king\\anaconda3\\lib\\site-packages (from transformers==3.0.0) (1.16.5)\n",
      "Collecting tokenizers==0.8.0-rc4 (from transformers==3.0.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/dd/88/a41502ef85240fbe6a970adf1f12c9b192f5fe6a5f5a168f2533d18fcbf6/tokenizers-0.8.0rc4-cp37-cp37m-win_amd64.whl (1.9MB)\n",
      "Requirement already satisfied: six in c:\\users\\king\\anaconda3\\lib\\site-packages (from sacremoses->transformers==3.0.0) (1.12.0)\n",
      "Requirement already satisfied: click in c:\\users\\king\\anaconda3\\lib\\site-packages (from sacremoses->transformers==3.0.0) (7.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\king\\anaconda3\\lib\\site-packages (from sacremoses->transformers==3.0.0) (0.13.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\king\\anaconda3\\lib\\site-packages (from requests->transformers==3.0.0) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\king\\anaconda3\\lib\\site-packages (from requests->transformers==3.0.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\king\\anaconda3\\lib\\site-packages (from requests->transformers==3.0.0) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\king\\anaconda3\\lib\\site-packages (from requests->transformers==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\king\\anaconda3\\lib\\site-packages (from packaging->transformers==3.0.0) (2.4.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=7e9430e29480572ffd72475d96f2644abd0c33b11ada730675effaf2b507dee6\n",
      "  Stored in directory: C:\\Users\\King\\AppData\\Local\\pip\\Cache\\wheels\\29\\3c\\fd\\7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: regex, sacremoses, tokenizers, transformers\n",
      "Successfully installed regex-2020.11.13 sacremoses-0.0.43 tokenizers-0.8.0rc4 transformers-3.0.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers==3.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x4giRzM7NtHJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKd-Tj3hOMsZ"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "cwJrQFQgN_BE",
    "outputId": "fbf8abc5-635e-432c-b70a-8648b0e9d9e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sharekhan's research repor on Housing Developm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Housing Development Finance Corporation (HDFC)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Reported Standalone quarterly numbers for Hous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Reported Consolidated quarterly numbers for Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>HDFC on November 2 posted a 27.55 percent year...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               Body\n",
       "0      1  Sharekhan's research repor on Housing Developm...\n",
       "1      1  Housing Development Finance Corporation (HDFC)...\n",
       "2      1  Reported Standalone quarterly numbers for Hous...\n",
       "3      1  Reported Consolidated quarterly numbers for Ho...\n",
       "4      1  HDFC on November 2 posted a 27.55 percent year..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"Labelled_news_data.csv\")\n",
    "df=df1.iloc[:,4:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzPPOrVQWiW5",
    "outputId": "8403d902-da60-4a8a-8508-86650497f9b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "676DPU1BOPdp",
    "outputId": "1b3f9f2b-1423-4ac0-fe82-bd18b820b20c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.818182\n",
       "0    0.181818\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class distribution\n",
    "df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKfWnApvOoE7"
   },
   "source": [
    "# Split train dataset into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mfhSPF5jOWb7"
   },
   "outputs": [],
   "source": [
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['Body'], df['label'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.4, \n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "# we will use temp_text and temp_labels to create validation and test set\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.9, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7hsdLoCO7uB"
   },
   "source": [
    "# Import BERT Model and BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1kY3gZjO2RE"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3be48e7999642449d9a5b66aefcb24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=433, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9598fcb4cb284a0b981971a80241afc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "_zOKeOMeO-DT"
   },
   "outputs": [],
   "source": [
    "# sample data\n",
    "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
    "\n",
    "# encode text\n",
    "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAH73n39PHLw",
    "outputId": "a425fdf7-f29a-4abe-bd77-ae1b4eee5630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "# output\n",
    "print(sent_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wIYaWI_Prg8"
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "yKwbpeN_PMiu",
    "outputId": "7bf2a007-6ccc-4f5f-92bd-c954be9f13a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4fd29b2550>"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "OXcswEIRPvGe"
   },
   "outputs": [],
   "source": [
    "max_seq_len = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "tk5S7DWaP2t6"
   },
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wsm8bkRZQTw9"
   },
   "source": [
    "# Convert Integer Sequences to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "QR-lXwmzQPd6"
   },
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "# for validation set\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "# for test set\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ov1cOBlcRLuk"
   },
   "source": [
    "# Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "qUy9JKFYQYLp"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2HZc5ZYRV28"
   },
   "source": [
    "# Freeze BERT Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "wHZ0MC00RQA_"
   },
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7ahGBUWRi3X"
   },
   "source": [
    "# Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "b3iEtGyYRd0A"
   },
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "      \n",
    "      super(BERT_Arch, self).__init__()\n",
    "\n",
    "      self.bert = bert \n",
    "      \n",
    "      # dropout layer\n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "      # relu activation function\n",
    "      self.relu =  nn.ReLU()\n",
    "\n",
    "      # dense layer 1\n",
    "      self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "      # dense layer 2 (Output layer)\n",
    "      self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "      #softmax activation function\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "      #pass the inputs to the model  \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "      \n",
    "      x = self.fc1(cls_hs)\n",
    "\n",
    "      x = self.relu(x)\n",
    "\n",
    "      x = self.dropout(x)\n",
    "\n",
    "      # output layer\n",
    "      x = self.fc2(x)\n",
    "      \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "cBAJJVuJRliv"
   },
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "taXS0IilRn9J"
   },
   "outputs": [],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9CDpoMQR_rK"
   },
   "source": [
    "# Find Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izY5xH5eR7Ur",
    "outputId": "5a27c5dc-9481-4a51-9eea-7baaf1f25a27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.73404255 0.61190476]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
    "\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "r1WvfY2vSGKi"
   },
   "outputs": [],
   "source": [
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "My4CA0qaShLq"
   },
   "source": [
    "# Fine-Tune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "rskLk8R_SahS"
   },
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    " \n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "yGXovFDlSxB5"
   },
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "  print(\"\\nEvaluating...\")\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      \n",
    "      # Calculate elapsed time in minutes.\n",
    "      elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "      # Report progress.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KZEgxRRTLXG"
   },
   "source": [
    "# Start Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k1USGTntS3TS",
    "outputId": "775852b3-9ee5-48ca-de7c-05c473f10e77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 5\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.690\n",
      "Validation Loss: 0.685\n",
      "\n",
      " Epoch 2 / 5\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.704\n",
      "Validation Loss: 0.680\n",
      "\n",
      " Epoch 3 / 5\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.698\n",
      "Validation Loss: 0.675\n",
      "\n",
      " Epoch 4 / 5\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.683\n",
      "Validation Loss: 0.673\n",
      "\n",
      " Epoch 5 / 5\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.759\n",
      "Validation Loss: 0.669\n"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yrhUc9kTI5a"
   },
   "source": [
    "# Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OacxUyizS8d1",
    "outputId": "0201d261-89f1-407b-e350-e7774902b405"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4SVftkkTZXA"
   },
   "source": [
    "# Get Predictions for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "NZl0SZmFTRQA"
   },
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "  preds = model(test_seq.to(device), test_mask.to(device))\n",
    "  preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ms1ObHZxTYSI",
    "outputId": "bfec0d9f-bccb-4b46-c480-4a60a7469391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.25      0.31        16\n",
      "           1       0.84      0.91      0.88        70\n",
      "\n",
      "    accuracy                           0.79        86\n",
      "   macro avg       0.62      0.58      0.59        86\n",
      "weighted avg       0.76      0.79      0.77        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "YqzLS7rHTp4T",
    "outputId": "d5cff5a9-3da4-46f4-b185-ab2a50bd276c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  0   1\n",
       "row_0       \n",
       "0      4  12\n",
       "1      6  64"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.crosstab(test_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpX1uTwjUPY6"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('saved_weights.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFPcd_Dnkpwr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Fine-Tuning BERT for Spam Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
